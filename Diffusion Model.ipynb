{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23c12b6-035b-43c8-b8ce-90161f92a7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate.utils import write_basic_config\n",
    "\n",
    "# write_basic_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7155420b-58a6-4aae-beba-3a4ab7b1efa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install imagen-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1865ab0-fb74-4f43-85a7-4d544e85919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c defaults intel-openmp -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d63bcdf-7702-4a3d-92f9-a67522fd0bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c pytorch pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcbebdb-0bbc-492a-a230-5cd2a9607077",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from imagen_pytorch import Unet, Imagen, SRUnet256, ImagenTrainer\n",
    "\n",
    "# unets for unconditional imagen\n",
    "\n",
    "unet1 = Unet(\n",
    "    dim = 32,\n",
    "    dim_mults = (1, 2, 4),\n",
    "    num_resnet_blocks = 3,\n",
    "    layer_attns = (False, True, True),\n",
    "    layer_cross_attns = False,\n",
    "    use_linear_attn = True\n",
    ")\n",
    "\n",
    "unet2 = SRUnet256(\n",
    "    dim = 32,\n",
    "    dim_mults = (1, 2, 4),\n",
    "    num_resnet_blocks = (2, 4, 8),\n",
    "    layer_attns = (False, False, True),\n",
    "    layer_cross_attns = False\n",
    ")\n",
    "\n",
    "# imagen, which contains the unets above (base unet and super resoluting ones)\n",
    "\n",
    "imagen = Imagen(\n",
    "    condition_on_text = False,   # this must be set to False for unconditional Imagen\n",
    "    unets = (unet1, unet2),\n",
    "    image_sizes = (64, 128),\n",
    "    timesteps = 1000\n",
    ")\n",
    "\n",
    "trainer = ImagenTrainer(imagen)\n",
    "\n",
    "# now get a ton of images and feed it through the Imagen trainer\n",
    "\n",
    "training_images = torch.randn(13800, 3, 256, 256)\n",
    "\n",
    "# train each unet separately\n",
    "# in this example, only training on unet number 1\n",
    "\n",
    "loss = trainer(training_images, unet_number = 1)\n",
    "trainer.update(unet_number = 1)\n",
    "\n",
    "# do the above for many many many many steps\n",
    "# now you can sample images unconditionally from the cascading unet(s)\n",
    "\n",
    "images = trainer.sample(batch_size = 16) # (16, 3, 128, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b21126-b7a3-44ae-b421-cc7dea1cec87",
   "metadata": {},
   "source": [
    "#### Using Data-loader to supply my own images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79800e06-8206-4d4a-859b-aed35c2aab32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Specify the path to your image folder\n",
    "image_folder = \"firstDataSetRun/\"\n",
    "\n",
    "# Define a transformation to preprocess the images\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize images to the required dimensions\n",
    "    transforms.ToTensor(),          # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize pixel values\n",
    "])\n",
    "\n",
    "# List to store processed images\n",
    "processed_images = []\n",
    "i=0\n",
    "# Loop through each image in the folder\n",
    "for filename in os.listdir(image_folder):\n",
    "    # Load the image\n",
    "    img_path = os.path.join(image_folder, filename)\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "    # Apply the preprocessing transformations\n",
    "    img_tensor = preprocess(img)\n",
    "\n",
    "    # Append the processed image to the list\n",
    "    processed_images.append(img_tensor)\n",
    "    print(f\"{i} done\")\n",
    "    i+=1\n",
    "\n",
    "# Stack the processed images into a single tensor\n",
    "training_images = torch.stack(processed_images)\n",
    "\n",
    "# Print the shape of the resulting tensor\n",
    "print(training_images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9028b45-8db2-4a8f-991a-9e9894b222c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from imagen_pytorch import Unet, Imagen, ImagenTrainer\n",
    "\n",
    "# unets for unconditional imagen\n",
    "\n",
    "unet1 = Unet(\n",
    "    dim = 32,\n",
    "    dim_mults = (1, 2, 4),\n",
    "    num_resnet_blocks = 3,\n",
    "    layer_attns = (False, True, True),\n",
    "    layer_cross_attns = False,\n",
    "    use_linear_attn = True\n",
    ")\n",
    "\n",
    "unet2 = SRUnet256(\n",
    "    dim = 32,\n",
    "    dim_mults = (1, 2, 4),\n",
    "    num_resnet_blocks = (2, 4, 8),\n",
    "    layer_attns = (False, False, True),\n",
    "    layer_cross_attns = False\n",
    ")\n",
    "\n",
    "# imagen, which contains the unets above (base unet and super resoluting ones)\n",
    "\n",
    "imagen = Imagen(\n",
    "    condition_on_text = False,   # this must be set to False for unconditional Imagen\n",
    "    unets = (unet1, unet2),\n",
    "    image_sizes = (64, 128),\n",
    "    timesteps = 1000\n",
    ")\n",
    "\n",
    "trainer = ImagenTrainer(imagen)\n",
    "\n",
    "# now get a ton of images and feed it through the Imagen trainer\n",
    "\n",
    "# training_images = torch.randn(4, 3, 256, 256)\n",
    "\n",
    "# train each unet separately\n",
    "# in this example, only training on unet number 1\n",
    "\n",
    "loss = trainer(training_images, unet_number = 1)\n",
    "trainer.update(unet_number = 1)\n",
    "\n",
    "# do the above for many many many many steps\n",
    "# now you can sample images unconditionally from the cascading unet(s)\n",
    "\n",
    "images = trainer.sample(batch_size = 16) # (16, 3, 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca85d0f-d270-453b-b1ec-0bb508858a0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d2c749-041c-496c-8afa-fcacb062cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.image_list = os.listdir(folder_path)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.folder_path, self.image_list[idx])\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "# Example usage:\n",
    "folder_path = \"firstDataSetRun\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = CustomImageDataset(\"firstDataSetRun\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Inspect the dataset by visualizing a few images\n",
    "def show_images(images):\n",
    "    fig, axs = plt.subplots(1, len(images), figsize=(12, 4))\n",
    "    for i, img in enumerate(images):\n",
    "        img_np = np.transpose(img.numpy(), (1, 2, 0))\n",
    "        axs[i].imshow(img_np)\n",
    "        axs[i].axis('off')\n",
    "        image_tensor = tf.convert_to_tensor(img)\n",
    "        # Get the dimensions of the image\n",
    "        print(image_tensor.shape)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Visualize a few batches of images\n",
    "for batch in dataloader:\n",
    "    show_images(batch)\n",
    "    break  # Break after the first batch to keep the example concise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35972184-95b2-4d10-9b13-093a554de463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagen_pytorch import Unet, Imagen, ImagenTrainer\n",
    "from imagen_pytorch.data import Dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# unets for unconditional imagen\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.image_list = os.listdir(folder_path)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.folder_path, self.image_list[idx])\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "# Example usage:\n",
    "# folder_path = \"firstDataSetRun\"\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((256, 256)),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "#####################################      FIRST TRY       #####################################\n",
    "# unet = Unet(\n",
    "#     dim = 32,\n",
    "#     dim_mults = (1, 2, 4, 8),\n",
    "#     num_resnet_blocks = 1,\n",
    "#     layer_attns = (False, False, False, True),\n",
    "#     layer_cross_attns = False\n",
    "# )\n",
    "\n",
    "#####################################     SECOND TRY WITH BIGGER MODEL      #####################################\n",
    "\n",
    "# unet = Unet(\n",
    "#     dim = 512,\n",
    "#     dim_mults = (1, 2, 4, 8),\n",
    "#     num_resnet_blocks= (2, 4, 8, 8),\n",
    "#     layer_attns = (False, True, True, True),\n",
    "#     layer_cross_attns = False,\n",
    "#     attn_heads= 8,\n",
    "#     memory_efficient= True\n",
    "# )\n",
    "\n",
    "# imagen = Imagen(\n",
    "#     condition_on_text = False,  # this must be set to False for unconditional Imagen\n",
    "#     unets = unet,\n",
    "#     image_sizes = 256,\n",
    "#     timesteps = 1000\n",
    "# )\n",
    "\n",
    "\n",
    "#####################################     THIRD TRY WITH BIGGER MODEL & 2 U-NETS      #####################################\n",
    "\n",
    "# unet1 = Unet(\n",
    "#     dim = 512,\n",
    "#     dim_mults = (1, 2, 4, 8),\n",
    "#     num_resnet_blocks: (2, 4, 8, 8)\n",
    "#     layer_attns = (False, True, True, True),\n",
    "#     layer_cross_attns = False,\n",
    "#     attn_heads: 8,\n",
    "#     memory_efficient: True\n",
    "# )\n",
    "\n",
    "# unet2 = BaseUnet64\n",
    "\n",
    "# imagen = Imagen(\n",
    "#     condition_on_text = False,  # this must be set to False for unconditional Imagen\n",
    "#     unets = (unet1, unet2),\n",
    "#     image_sizes = 256,\n",
    "#     timesteps = 1000\n",
    "# )\n",
    "#####################################     THIRD TRY WITH MODEL ARC. FROM PAPER      #####################################\n",
    "\n",
    "unet1 = Unet(\n",
    "    dim=32,\n",
    "    dim_mults=(1, 2, 4),\n",
    "    num_resnet_blocks=3,\n",
    "    layer_attns=(False, True, True),\n",
    "    layer_cross_attns=(False, True, True),\n",
    "    use_linear_attn=True,\n",
    ")\n",
    "\n",
    "unet2 = Unet(\n",
    "        dim=64,\n",
    "        dim_mults=(1, 2, 4),\n",
    "        num_resnet_blocks=3,\n",
    "        layer_attns=(False, True, True),\n",
    "        layer_cross_attns=(False, True, True),\n",
    "        use_linear_attn=True,\n",
    ")\n",
    "\n",
    "imagen = Imagen(\n",
    "    condition_on_text = False,  # this must be set to False for unconditional Imagen\n",
    "    unets = [unet1, unet2],\n",
    "    image_sizes = 64,\n",
    "    timesteps = 1000\n",
    ")\n",
    "###############################################################################################################\n",
    "\n",
    "trainer = ImagenTrainer(\n",
    "    imagen = imagen,\n",
    "    split_valid_from_train = True # whether to split the validation dataset from the training\n",
    ")\n",
    "\n",
    "# instantiate your dataloader, which returns the necessary inputs to the DDPM as tuple in the order of images, text embeddings, then text masks. in this case, only images is returned as it is unconditional training\n",
    "\n",
    "\n",
    "# working training loop\n",
    "\n",
    "total_epochs = 10\n",
    "\n",
    "\n",
    "print(\"Going into training loop\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_folder = sys.argv[1]\n",
    "    batch_size_training=sys.argv[2]\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    dataset = Dataset(data_folder, image_size = 64)\n",
    "    trainer.add_train_dataset(dataset, batch_size = batch_size_training)\n",
    "\n",
    "    np.random.seed(2018)\n",
    "\n",
    "    start_time_main=time.time()\n",
    "\n",
    "    for i in range(250000):\n",
    "        loss = trainer.train_step(unet_number = 1, max_batch_size = 4)\n",
    "        print(f'loss: {loss}')\n",
    "        \n",
    "        if not (i % 50):\n",
    "            valid_loss = trainer.valid_step(unet_number = 1, max_batch_size = 4)\n",
    "            print(f'valid loss: {valid_loss}')\n",
    "    \n",
    "        if not (i % 100) and trainer.is_main: # is_main makes sure this can run in distributed\n",
    "            images = trainer.sample(batch_size = 1, return_pil_images = True) # returns List[Image]\n",
    "            images[0].save(f'./sample-{i // 100}.png')\n",
    "            trainer.save('largerModelWithCorrectData.pt')\n",
    "    stop_time_main = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Execution time: {elapsed_time}\")\n",
    "    \n",
    "    \n",
    "    # for epoch in range(total_epochs):\n",
    "    #     print(f\"epoch {epoch}\")\n",
    "    #     for batch_data in dataloader:\n",
    "    #         print(f\"batch\")\n",
    "    #         loss = trainer.train_step(unet_number=1, max_batch_size=batch_size_training)\n",
    "    #         print(f'Epoch {epoch + 1}, Loss: {loss}')\n",
    "    \n",
    "    #     # Validation at the end of each epoch\n",
    "    #     valid_loss = trainer.valid_step(unet_number=1, max_batch_size=batch_size_training)\n",
    "    #     print(f'Validation Loss: {valid_loss}')\n",
    "    \n",
    "    #     if trainer.is_main:\n",
    "    #         # Image sampling every 2 epochs\n",
    "    #         if epoch % 2 == 0:\n",
    "    #             images = trainer.sample(batch_size=1, return_pil_images=True)\n",
    "    #             images[0].save(f'./sample-{epoch // 2}.png')\n",
    "    #     epoch+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455513e9-1c46-408d-befc-7b74abb733b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(200000):\n",
    "#     loss = trainer.train_step(unet_number = 1, max_batch_size = 4)\n",
    "#     print(f'loss: {loss}')\n",
    "\n",
    "#     if not (i % 50):\n",
    "#         valid_loss = trainer.valid_step(unet_number = 1, max_batch_size = 4)\n",
    "#         print(f'valid loss: {valid_loss}')\n",
    "\n",
    "#     if not (i % 100) and trainer.is_main: # is_main makes sure this can run in distributed\n",
    "#         images = trainer.sample(batch_size = 1, return_pil_images = True) # returns List[Image]\n",
    "#         images[0].save(f'./sample-{i // 100}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26526cbd-1c7c-41b2-a062-459a923e970e",
   "metadata": {},
   "source": [
    "### BASE3.PY Troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e726586-e057-4c2a-bab7-308e85139301",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from imagen_pytorch import Unet, Imagen, ImagenTrainer, BaseUnet64\n",
    "from imagen_pytorch.data import Dataset\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# unets for unconditional imagen\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.image_list = os.listdir(folder_path)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.folder_path, self.image_list[idx])\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "#####################################     THIRD TRY WITH BIGGER MODEL & 2 U-NETS      #####################################\n",
    "unet1 = Unet(\n",
    "    dim=32,\n",
    "    dim_mults=(1, 2, 4),\n",
    "    num_resnet_blocks=3,\n",
    "    layer_attns=(False, True, True),\n",
    "    layer_cross_attns=(False, True, True),\n",
    "    use_linear_attn=True,\n",
    ")\n",
    "\n",
    "unet2 = BaseUnet64()\n",
    "\n",
    "imagen = Imagen(\n",
    "    condition_on_text = False,  # this must be set to False for unconditional Imagen\n",
    "    unets = [unet1, unet2],\n",
    "    # channels=1,\n",
    "    image_sizes=(32, 64),\n",
    "    timesteps = 1000\n",
    ")\n",
    "\n",
    "\n",
    "trainer = ImagenTrainer(\n",
    "    imagen = imagen,\n",
    "    split_valid_from_train = True # whether to split the validation dataset from the training\n",
    ")\n",
    "\n",
    "# instantiate your dataloader, which returns the necessary inputs to the DDPM as tuple in the order of images, text embeddings, then text masks. in this case, only images is returned as it is unconditional training\n",
    "\n",
    "\n",
    "# working training loop\n",
    "\n",
    "total_epochs = 10\n",
    "\n",
    "\n",
    "print(\"Going into training loop\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_folder = \"firstDataSetRun\" # sys.argv[0]\n",
    "    batch_size_training= 16 #sys.argv[1]\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    dataset = Dataset(data_folder, image_size = 64)\n",
    "    trainer.add_train_dataset(dataset, batch_size = batch_size_training)\n",
    "\n",
    "    np.random.seed(2018)\n",
    "\n",
    "    start_time_main=time.time()\n",
    "\n",
    "    # for i in range(300000):\n",
    "    #     for u in range(1,2):\n",
    "    #         loss = trainer(training_images, unet_number=u, max_batch_size=max_batch_size)\n",
    "    #         trainer.update(unet_number=u)\n",
    "    \n",
    "    # images = trainer.sample(batch_size=16, return_pil_images=True)\n",
    "    # trainer.save('largerModelWithCorrectData.pt')\n",
    "    # stop_time_main = time.time()\n",
    "    # elapsed_time = end_time - start_time\n",
    "    # print(f\"Execution time: {elapsed_time}\")\n",
    "\n",
    "    for i in range(200000):\n",
    "        for u in range(1, 3):  # Loop over both U-Nets\n",
    "            # Training step\n",
    "            loss = trainer.train_step(unet_number=u, max_batch_size=4)\n",
    "            print(f'Training loss at step {i} for U-Net {u}: {loss}')\n",
    "    \n",
    "            # Validation step every 50 steps\n",
    "            if i % 50 == 0:\n",
    "                valid_loss = trainer.valid_step(unet_number=u, max_batch_size=4)\n",
    "                print(f'Validation loss at step {i} for U-Net {u}: {valid_loss}')\n",
    "    \n",
    "            # Save a sample image every 100 steps\n",
    "            if i % 100 == 0 and trainer.is_main:  # is_main ensures this can run in distributed mode\n",
    "                images = trainer.sample(batch_size=1, unet_number=u, return_pil_images=True)  # returns List[Image]\n",
    "                images[0].save(f'./sample-{u}-{i // 100}.png')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # for i in range(300000):\n",
    "    #     for u in range(1,2)\n",
    "    #     loss = trainer.train_step(unet_number = u, max_batch_size = 4)\n",
    "    #     print(f'loss: {loss}')\n",
    "        \n",
    "    #     if not (i % 50):\n",
    "    #         valid_loss = trainer.valid_step(unet_number = u, max_batch_size = 4)\n",
    "    #         print(f'valid loss: {valid_loss}')\n",
    "    \n",
    "    #     if not (i % 100) and trainer.is_main: # is_main makes sure this can run in distributed\n",
    "    #         images = trainer.sample(batch_size = 1, return_pil_images = True) # returns List[Image]\n",
    "    #         images[0].save(f'./sample-{i // 100}.png')\n",
    "    #         trainer.save('largerModelWithCorrectData.pt')\n",
    "    # stop_time_main = time.time()\n",
    "    # elapsed_time = end_time - start_time\n",
    "    # print(f\"Execution time: {elapsed_time}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d126f2f-8b9c-42e1-beb8-b7ec042cfb76",
   "metadata": {},
   "outputs": [],
   "source": [
    " for i in range(200000):\n",
    "    # Training step\n",
    "    loss = trainer.train_step(only_train_unet_number=1, max_batch_size=4)\n",
    "    print(f'Training loss at step {i} for U-Net 1: {loss}')\n",
    "\n",
    "    # Validation step every 50 steps\n",
    "    if i % 50 == 0:\n",
    "        valid_loss = trainer.valid_step(unet_number=1, max_batch_size=4)\n",
    "        print(f'Validation loss at step {i} for U-Net 1: {valid_loss}')\n",
    "\n",
    " for i in range(200000):\n",
    "    # Training step\n",
    "    loss = trainer.train_step(only_train_unet_number=2, max_batch_size=4)\n",
    "    print(f'Training loss at step {i} for U-Net 2: {loss}')\n",
    "\n",
    "    # Validation step every 50 steps\n",
    "    if i % 50 == 0:\n",
    "        valid_loss = trainer.valid_step(unet_number=2, max_batch_size=4)\n",
    "        print(f'Validation loss at step {i} for U-Net 2: {valid_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a79dea6-60e0-40e3-b95b-e89c65cfb412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from imagen_pytorch import Unet, Imagen, SRUnet256, ImagenTrainer\n",
    "\n",
    "# unets for unconditional imagen\n",
    "\n",
    "unet1 = Unet(\n",
    "    dim = 128,\n",
    "    dim_mults = (1, 2, 4),\n",
    "    num_resnet_blocks = 0,\n",
    "    layer_attns = (False, True, True),\n",
    "    layer_cross_attns = False,\n",
    "    use_linear_attn = True\n",
    ")\n",
    "\n",
    "\n",
    "# imagen, which contains the unets above (base unet and super resoluting ones)\n",
    "\n",
    "imagen = Imagen(\n",
    "    condition_on_text = False,   # this must be set to False for unconditional Imagen\n",
    "    unets = (unet1),\n",
    "    image_sizes = (256),\n",
    "    timesteps = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66e656d-a4e1-42c2-a4f0-cf44f5118381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
